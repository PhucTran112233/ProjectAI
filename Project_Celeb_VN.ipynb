{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Celeb-VN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2vQwFOdp99YjccvpVgQE5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhucTran112233/ProjectAI/blob/main/Project_Celeb_VN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJJg4k2T6oYo",
        "outputId": "f4acdb40-f349-4602-834e-997e501d2fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# liên kết Google drive với colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tải thư viện cần thiết\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,Activation,Dropout,Conv2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.models import  Sequential\n",
        "from keras import regularizers\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "nhBWjdX36xKS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = '/content/drive/MyDrive/AI/Train'\n",
        "val_data =  '/content/drive/MyDrive/AI/Validation'"
      ],
      "metadata": {
        "id": "tEP5vocW6ymV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing\n",
        "train_scale = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=0.2,\n",
        "                                   width_shift_range=0.2,   \n",
        "                                   height_shift_range=0.2,\n",
        "                                   horizontal_flip=True, \n",
        "                                   vertical_flip=True,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "train_input = train_scale.flow_from_directory(train_data,\n",
        "                        target_size=(128, 128),\n",
        "                        batch_size=32,\n",
        "                        class_mode=\"categorical\")\n",
        "\n",
        "val_scale = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_input = val_scale.flow_from_directory(val_data,\n",
        "                        target_size=(128,128),\n",
        "                        batch_size=32,\n",
        "                        class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kEqg6xH9T6D",
        "outputId": "131084cc-2255-4349-8bf9-49286d196447"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1192 images belonging to 26 classes.\n",
            "Found 128 images belonging to 26 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"match class: \", train_input.class_indices)\n",
        "print(\"Tổng cộng: \",train_input.num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76cYrqCc6-sa",
        "outputId": "51707a30-e778-47a3-a653-3ed1780d46dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "match class:  {'Ánh Viên': 0, 'Chí Tài': 1, 'Huỳnh Phương': 2, 'Lí Hải': 3, 'MC Lại Văn Sâm': 4, 'MC Đại Nghĩa': 5, 'Mạc Văn khoa': 6, 'Misthy': 7, 'NSUT Hồng Vân': 8, 'NSUT Tự Long': 9, 'Nguyễn Huy Hoàng': 10, 'Nguyễn Thị Kim Ngân': 11, 'Nhật Anh Trắng': 12, 'PewPew': 13, 'Phan Mạnh Quỳnh': 14, 'Phạm Nhật Vượng': 15, 'Quang Thắng': 16, 'Ribi Sachi Thuỷ': 17, 'Sơn Tùng MTP': 18, 'Sỹ Luân': 19, 'TT Nguyễn Xuân Phúc': 20, 'Vân Dung': 21, 'ViruSs': 22, 'Vũ Cát Tường': 23, 'Đàm Vĩnh Hưng': 24, 'Đen Vâu': 25}\n",
            "Tổng cộng:  26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL CNN\n",
        "model=Sequential()\n",
        "#TRÍCH XUẤT TẬP DỮ LIỆU(FEATURE EXTRACTORS)\n",
        "#LAYER 1\n",
        "model.add(Conv2D(64,(5,5),activation='relu',padding='same', input_shape=(128,128,3)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "#LAYER 2\n",
        "model.add(Conv2D(256,(3,3),activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "#LAYER 3\n",
        "model.add(Conv2D(512,(3,3),activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "#LAYER 4\n",
        "model.add(Conv2D(1024,(3,3),activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#FULLY CONNECTED LAYER\n",
        "#Flatten Layer is used to change the dimension of output from convolution layer, which has 3D, to 2D output\n",
        "model.add(Flatten())\n",
        "#Dense\n",
        "model.add(Dense(4096,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(26,activation='softmax'))  \n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jJhSxGv7D-f",
        "outputId": "e1fc48b1-96b6-4576-f9de-4d9868e99d9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 64)      4864      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 256)       147712    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 1024)      4719616   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 8, 1024)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8, 8, 1024)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              268439552 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 26)                106522    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 291,379,738\n",
            "Trainable params: 291,379,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XAuXAY1v7Q5v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "ckpoint = ModelCheckpoint(\"models.json\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\")"
      ],
      "metadata": {
        "id": "b9ie7wZR7T8w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_celeb_train = model.fit(train_input,batch_size=32,epochs=300,verbose=1,validation_data=val_input,callbacks=ckpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uZDWiCX7Xhq",
        "outputId": "82201106-0fa5-4a26-8255-c13cb2e3da9b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 4.1756 - accuracy: 0.0529INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 395s 10s/step - loss: 4.1756 - accuracy: 0.0529 - val_loss: 3.2699 - val_accuracy: 0.0234\n",
            "Epoch 2/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 3.2213 - accuracy: 0.0529INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 26s 691ms/step - loss: 3.2213 - accuracy: 0.0529 - val_loss: 3.2965 - val_accuracy: 0.0312\n",
            "Epoch 3/300\n",
            "38/38 [==============================] - 10s 253ms/step - loss: 3.2093 - accuracy: 0.0554 - val_loss: 3.3487 - val_accuracy: 0.0234\n",
            "Epoch 4/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 3.2096 - accuracy: 0.0545INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 668ms/step - loss: 3.2096 - accuracy: 0.0545 - val_loss: 3.3857 - val_accuracy: 0.0547\n",
            "Epoch 5/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 3.1977 - accuracy: 0.0520 - val_loss: 3.3960 - val_accuracy: 0.0547\n",
            "Epoch 6/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 3.1754 - accuracy: 0.0940INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 26s 685ms/step - loss: 3.1754 - accuracy: 0.0940 - val_loss: 3.2493 - val_accuracy: 0.0625\n",
            "Epoch 7/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 3.1519 - accuracy: 0.1007INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 662ms/step - loss: 3.1519 - accuracy: 0.1007 - val_loss: 3.1911 - val_accuracy: 0.0859\n",
            "Epoch 8/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 3.1064 - accuracy: 0.1158 - val_loss: 3.4414 - val_accuracy: 0.0547\n",
            "Epoch 9/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 3.0788 - accuracy: 0.1149 - val_loss: 3.2867 - val_accuracy: 0.0703\n",
            "Epoch 10/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 3.0648 - accuracy: 0.1258INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 668ms/step - loss: 3.0648 - accuracy: 0.1258 - val_loss: 3.1602 - val_accuracy: 0.0938\n",
            "Epoch 11/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 3.1036 - accuracy: 0.1057 - val_loss: 3.1635 - val_accuracy: 0.0703\n",
            "Epoch 12/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 3.0549 - accuracy: 0.1242INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 669ms/step - loss: 3.0549 - accuracy: 0.1242 - val_loss: 3.0970 - val_accuracy: 0.1016\n",
            "Epoch 13/300\n",
            "38/38 [==============================] - 9s 240ms/step - loss: 3.0099 - accuracy: 0.1351 - val_loss: 3.1084 - val_accuracy: 0.0938\n",
            "Epoch 14/300\n",
            "38/38 [==============================] - 9s 245ms/step - loss: 3.0807 - accuracy: 0.1158 - val_loss: 3.0821 - val_accuracy: 0.0859\n",
            "Epoch 15/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 2.9926 - accuracy: 0.1460 - val_loss: 3.0224 - val_accuracy: 0.1016\n",
            "Epoch 16/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.9706 - accuracy: 0.1477INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 669ms/step - loss: 2.9706 - accuracy: 0.1477 - val_loss: 3.0169 - val_accuracy: 0.1250\n",
            "Epoch 17/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.9796 - accuracy: 0.1418INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 660ms/step - loss: 2.9796 - accuracy: 0.1418 - val_loss: 2.9999 - val_accuracy: 0.1562\n",
            "Epoch 18/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 2.9898 - accuracy: 0.1351 - val_loss: 3.0434 - val_accuracy: 0.1094\n",
            "Epoch 19/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 2.9294 - accuracy: 0.1560 - val_loss: 2.9956 - val_accuracy: 0.1172\n",
            "Epoch 20/300\n",
            "38/38 [==============================] - 9s 239ms/step - loss: 2.9760 - accuracy: 0.1409 - val_loss: 2.9863 - val_accuracy: 0.1250\n",
            "Epoch 21/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 2.9116 - accuracy: 0.1762 - val_loss: 2.9710 - val_accuracy: 0.1328\n",
            "Epoch 22/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.8684 - accuracy: 0.1711INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 659ms/step - loss: 2.8684 - accuracy: 0.1711 - val_loss: 2.9386 - val_accuracy: 0.1641\n",
            "Epoch 23/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 2.8744 - accuracy: 0.1745 - val_loss: 2.9388 - val_accuracy: 0.1484\n",
            "Epoch 24/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.8815 - accuracy: 0.1745INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 669ms/step - loss: 2.8815 - accuracy: 0.1745 - val_loss: 2.8751 - val_accuracy: 0.1953\n",
            "Epoch 25/300\n",
            "38/38 [==============================] - 10s 251ms/step - loss: 2.8500 - accuracy: 0.1737 - val_loss: 2.9521 - val_accuracy: 0.1562\n",
            "Epoch 26/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 2.8100 - accuracy: 0.2022 - val_loss: 2.8955 - val_accuracy: 0.1328\n",
            "Epoch 27/300\n",
            "38/38 [==============================] - 9s 240ms/step - loss: 2.7911 - accuracy: 0.1879 - val_loss: 3.0411 - val_accuracy: 0.0938\n",
            "Epoch 28/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 2.7986 - accuracy: 0.1846 - val_loss: 2.9365 - val_accuracy: 0.1250\n",
            "Epoch 29/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 2.8073 - accuracy: 0.1955 - val_loss: 2.9723 - val_accuracy: 0.1562\n",
            "Epoch 30/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 2.7939 - accuracy: 0.1862 - val_loss: 2.9638 - val_accuracy: 0.1484\n",
            "Epoch 31/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 2.7870 - accuracy: 0.1938 - val_loss: 2.9526 - val_accuracy: 0.1484\n",
            "Epoch 32/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 2.7466 - accuracy: 0.2089 - val_loss: 2.8491 - val_accuracy: 0.1562\n",
            "Epoch 33/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.7917 - accuracy: 0.1904 - val_loss: 2.9395 - val_accuracy: 0.1484\n",
            "Epoch 34/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 2.7468 - accuracy: 0.2081 - val_loss: 2.7819 - val_accuracy: 0.1797\n",
            "Epoch 35/300\n",
            "38/38 [==============================] - 10s 272ms/step - loss: 2.7183 - accuracy: 0.2131 - val_loss: 2.8896 - val_accuracy: 0.1875\n",
            "Epoch 36/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.6763 - accuracy: 0.2215 - val_loss: 2.9128 - val_accuracy: 0.1484\n",
            "Epoch 37/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 2.7143 - accuracy: 0.2307 - val_loss: 2.7759 - val_accuracy: 0.1797\n",
            "Epoch 38/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.7100 - accuracy: 0.2248INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 662ms/step - loss: 2.7100 - accuracy: 0.2248 - val_loss: 2.7596 - val_accuracy: 0.2031\n",
            "Epoch 39/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 2.6776 - accuracy: 0.2215 - val_loss: 2.8702 - val_accuracy: 0.1719\n",
            "Epoch 40/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.6859 - accuracy: 0.2232INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 667ms/step - loss: 2.6859 - accuracy: 0.2232 - val_loss: 2.6355 - val_accuracy: 0.2578\n",
            "Epoch 41/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.6221 - accuracy: 0.2315INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 658ms/step - loss: 2.6221 - accuracy: 0.2315 - val_loss: 2.6102 - val_accuracy: 0.3047\n",
            "Epoch 42/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 2.6850 - accuracy: 0.2013 - val_loss: 2.8135 - val_accuracy: 0.1328\n",
            "Epoch 43/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.6162 - accuracy: 0.2315 - val_loss: 2.7856 - val_accuracy: 0.1562\n",
            "Epoch 44/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 2.6125 - accuracy: 0.2408 - val_loss: 2.7584 - val_accuracy: 0.2031\n",
            "Epoch 45/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 2.5794 - accuracy: 0.2383 - val_loss: 2.8198 - val_accuracy: 0.1719\n",
            "Epoch 46/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 2.6256 - accuracy: 0.2257 - val_loss: 2.8164 - val_accuracy: 0.1719\n",
            "Epoch 47/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 2.5701 - accuracy: 0.2349 - val_loss: 2.6610 - val_accuracy: 0.2188\n",
            "Epoch 48/300\n",
            "38/38 [==============================] - 9s 231ms/step - loss: 2.5635 - accuracy: 0.2408 - val_loss: 2.6670 - val_accuracy: 0.2578\n",
            "Epoch 49/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 2.5561 - accuracy: 0.2735 - val_loss: 2.7625 - val_accuracy: 0.2109\n",
            "Epoch 50/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.5867 - accuracy: 0.2492 - val_loss: 2.6083 - val_accuracy: 0.2656\n",
            "Epoch 51/300\n",
            "38/38 [==============================] - 9s 230ms/step - loss: 2.5677 - accuracy: 0.2282 - val_loss: 2.5741 - val_accuracy: 0.2500\n",
            "Epoch 52/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 2.5046 - accuracy: 0.2508 - val_loss: 2.5027 - val_accuracy: 0.2578\n",
            "Epoch 53/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 2.5162 - accuracy: 0.2584 - val_loss: 2.6722 - val_accuracy: 0.2266\n",
            "Epoch 54/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.5433 - accuracy: 0.2550 - val_loss: 2.6117 - val_accuracy: 0.2031\n",
            "Epoch 55/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.4998 - accuracy: 0.2508 - val_loss: 2.5023 - val_accuracy: 0.2344\n",
            "Epoch 56/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 2.4879 - accuracy: 0.2651 - val_loss: 2.4134 - val_accuracy: 0.2812\n",
            "Epoch 57/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 2.4342 - accuracy: 0.2903 - val_loss: 2.4972 - val_accuracy: 0.2578\n",
            "Epoch 58/300\n",
            "38/38 [==============================] - 9s 230ms/step - loss: 2.5117 - accuracy: 0.2567 - val_loss: 2.4954 - val_accuracy: 0.2891\n",
            "Epoch 59/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.4411 - accuracy: 0.2861 - val_loss: 2.3674 - val_accuracy: 0.3047\n",
            "Epoch 60/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.4701 - accuracy: 0.2827 - val_loss: 2.9630 - val_accuracy: 0.1953\n",
            "Epoch 61/300\n",
            "38/38 [==============================] - 10s 253ms/step - loss: 2.4518 - accuracy: 0.2802 - val_loss: 2.4724 - val_accuracy: 0.2656\n",
            "Epoch 62/300\n",
            "38/38 [==============================] - 9s 241ms/step - loss: 2.4281 - accuracy: 0.2735 - val_loss: 2.3492 - val_accuracy: 0.3047\n",
            "Epoch 63/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 2.3856 - accuracy: 0.3037 - val_loss: 2.3318 - val_accuracy: 0.3047\n",
            "Epoch 64/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.3780 - accuracy: 0.2936INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 663ms/step - loss: 2.3780 - accuracy: 0.2936 - val_loss: 2.2334 - val_accuracy: 0.3359\n",
            "Epoch 65/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.3547 - accuracy: 0.3020INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 657ms/step - loss: 2.3547 - accuracy: 0.3020 - val_loss: 2.4015 - val_accuracy: 0.3516\n",
            "Epoch 66/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 2.3132 - accuracy: 0.3112 - val_loss: 2.3267 - val_accuracy: 0.3359\n",
            "Epoch 67/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 2.3124 - accuracy: 0.3070 - val_loss: 2.3100 - val_accuracy: 0.2891\n",
            "Epoch 68/300\n",
            "38/38 [==============================] - 9s 231ms/step - loss: 2.3700 - accuracy: 0.3037 - val_loss: 2.3582 - val_accuracy: 0.2891\n",
            "Epoch 69/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 2.4303 - accuracy: 0.2886 - val_loss: 2.3415 - val_accuracy: 0.3203\n",
            "Epoch 70/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 2.3161 - accuracy: 0.3087 - val_loss: 2.4222 - val_accuracy: 0.3203\n",
            "Epoch 71/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 2.2804 - accuracy: 0.3238 - val_loss: 2.3084 - val_accuracy: 0.3281\n",
            "Epoch 72/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.2802 - accuracy: 0.3230 - val_loss: 2.3918 - val_accuracy: 0.3047\n",
            "Epoch 73/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 2.2801 - accuracy: 0.3221 - val_loss: 2.6710 - val_accuracy: 0.2734\n",
            "Epoch 74/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 2.2894 - accuracy: 0.3331 - val_loss: 2.1537 - val_accuracy: 0.3516\n",
            "Epoch 75/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 2.2513 - accuracy: 0.3213 - val_loss: 2.2684 - val_accuracy: 0.3125\n",
            "Epoch 76/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 2.2723 - accuracy: 0.3289 - val_loss: 2.1569 - val_accuracy: 0.3516\n",
            "Epoch 77/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.2578 - accuracy: 0.3213 - val_loss: 2.2786 - val_accuracy: 0.3125\n",
            "Epoch 78/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 2.2065 - accuracy: 0.3473 - val_loss: 2.1640 - val_accuracy: 0.3125\n",
            "Epoch 79/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.1933 - accuracy: 0.3414INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 658ms/step - loss: 2.1933 - accuracy: 0.3414 - val_loss: 2.1130 - val_accuracy: 0.4141\n",
            "Epoch 80/300\n",
            "38/38 [==============================] - 9s 231ms/step - loss: 2.2059 - accuracy: 0.3473 - val_loss: 2.1745 - val_accuracy: 0.3516\n",
            "Epoch 81/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.2738 - accuracy: 0.3372 - val_loss: 2.1961 - val_accuracy: 0.3672\n",
            "Epoch 82/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 2.3245 - accuracy: 0.3104 - val_loss: 2.2810 - val_accuracy: 0.2969\n",
            "Epoch 83/300\n",
            "38/38 [==============================] - 9s 231ms/step - loss: 2.2496 - accuracy: 0.3272 - val_loss: 2.2441 - val_accuracy: 0.3203\n",
            "Epoch 84/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.2115 - accuracy: 0.3398 - val_loss: 2.0267 - val_accuracy: 0.3984\n",
            "Epoch 85/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 2.1925 - accuracy: 0.3347 - val_loss: 2.2963 - val_accuracy: 0.2812\n",
            "Epoch 86/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.1693 - accuracy: 0.3574 - val_loss: 2.0841 - val_accuracy: 0.3672\n",
            "Epoch 87/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 2.1666 - accuracy: 0.3465 - val_loss: 2.1404 - val_accuracy: 0.3594\n",
            "Epoch 88/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 2.1217 - accuracy: 0.3549 - val_loss: 2.0992 - val_accuracy: 0.4062\n",
            "Epoch 89/300\n",
            "38/38 [==============================] - 10s 274ms/step - loss: 2.1048 - accuracy: 0.3658 - val_loss: 2.6098 - val_accuracy: 0.2734\n",
            "Epoch 90/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 2.1444 - accuracy: 0.3574 - val_loss: 2.1394 - val_accuracy: 0.3281\n",
            "Epoch 91/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.1526 - accuracy: 0.3582INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 663ms/step - loss: 2.1526 - accuracy: 0.3582 - val_loss: 2.0295 - val_accuracy: 0.4219\n",
            "Epoch 92/300\n",
            "38/38 [==============================] - 9s 230ms/step - loss: 2.1438 - accuracy: 0.3599 - val_loss: 1.9852 - val_accuracy: 0.3984\n",
            "Epoch 93/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 2.0947 - accuracy: 0.3725 - val_loss: 2.1636 - val_accuracy: 0.3984\n",
            "Epoch 94/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.0746 - accuracy: 0.3557 - val_loss: 1.9421 - val_accuracy: 0.3828\n",
            "Epoch 95/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 2.0652 - accuracy: 0.3943 - val_loss: 2.1079 - val_accuracy: 0.3906\n",
            "Epoch 96/300\n",
            "38/38 [==============================] - 9s 231ms/step - loss: 2.1218 - accuracy: 0.3658 - val_loss: 2.1430 - val_accuracy: 0.3516\n",
            "Epoch 97/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 2.0281 - accuracy: 0.3859 - val_loss: 1.9894 - val_accuracy: 0.4062\n",
            "Epoch 98/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.0215 - accuracy: 0.3784INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 664ms/step - loss: 2.0215 - accuracy: 0.3784 - val_loss: 1.8640 - val_accuracy: 0.4531\n",
            "Epoch 99/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.0121 - accuracy: 0.3884INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 665ms/step - loss: 2.0121 - accuracy: 0.3884 - val_loss: 1.8488 - val_accuracy: 0.4688\n",
            "Epoch 100/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 2.0132 - accuracy: 0.3993 - val_loss: 1.8951 - val_accuracy: 0.3984\n",
            "Epoch 101/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.9880 - accuracy: 0.4136 - val_loss: 2.2815 - val_accuracy: 0.3438\n",
            "Epoch 102/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.9940 - accuracy: 0.3842 - val_loss: 1.9065 - val_accuracy: 0.4375\n",
            "Epoch 103/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 2.0015 - accuracy: 0.3750 - val_loss: 2.0830 - val_accuracy: 0.3828\n",
            "Epoch 104/300\n",
            "38/38 [==============================] - 9s 239ms/step - loss: 1.9564 - accuracy: 0.4044 - val_loss: 1.9851 - val_accuracy: 0.4141\n",
            "Epoch 105/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 1.9592 - accuracy: 0.3960 - val_loss: 2.0029 - val_accuracy: 0.3828\n",
            "Epoch 106/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.8842 - accuracy: 0.4388INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 659ms/step - loss: 1.8842 - accuracy: 0.4388 - val_loss: 1.8451 - val_accuracy: 0.4844\n",
            "Epoch 107/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 1.9062 - accuracy: 0.4245 - val_loss: 1.8017 - val_accuracy: 0.4688\n",
            "Epoch 108/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 1.9301 - accuracy: 0.4128 - val_loss: 2.1634 - val_accuracy: 0.3672\n",
            "Epoch 109/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.9010 - accuracy: 0.4228 - val_loss: 1.8911 - val_accuracy: 0.4219\n",
            "Epoch 110/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.9006 - accuracy: 0.4279 - val_loss: 1.7942 - val_accuracy: 0.4141\n",
            "Epoch 111/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.7938 - accuracy: 0.4555 - val_loss: 1.9120 - val_accuracy: 0.4297\n",
            "Epoch 112/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.8526 - accuracy: 0.4539 - val_loss: 2.0034 - val_accuracy: 0.3906\n",
            "Epoch 113/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.8998 - accuracy: 0.4186INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 662ms/step - loss: 1.8998 - accuracy: 0.4186 - val_loss: 1.7197 - val_accuracy: 0.4922\n",
            "Epoch 114/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.9285 - accuracy: 0.4203 - val_loss: 1.9401 - val_accuracy: 0.3984\n",
            "Epoch 115/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.8683 - accuracy: 0.4279 - val_loss: 1.7643 - val_accuracy: 0.4922\n",
            "Epoch 116/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.8315 - accuracy: 0.4362 - val_loss: 1.8912 - val_accuracy: 0.4453\n",
            "Epoch 117/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.8785 - accuracy: 0.4228 - val_loss: 1.8170 - val_accuracy: 0.4375\n",
            "Epoch 118/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 1.8214 - accuracy: 0.4362 - val_loss: 1.9171 - val_accuracy: 0.4141\n",
            "Epoch 119/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.7975 - accuracy: 0.4631 - val_loss: 1.6905 - val_accuracy: 0.4609\n",
            "Epoch 120/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.8112 - accuracy: 0.4572INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 665ms/step - loss: 1.8112 - accuracy: 0.4572 - val_loss: 1.7323 - val_accuracy: 0.5078\n",
            "Epoch 121/300\n",
            "38/38 [==============================] - 9s 239ms/step - loss: 1.7640 - accuracy: 0.4664 - val_loss: 1.8550 - val_accuracy: 0.4453\n",
            "Epoch 122/300\n",
            "38/38 [==============================] - 9s 241ms/step - loss: 1.7882 - accuracy: 0.4539 - val_loss: 2.0283 - val_accuracy: 0.4141\n",
            "Epoch 123/300\n",
            "38/38 [==============================] - 9s 239ms/step - loss: 1.7720 - accuracy: 0.4690 - val_loss: 1.9370 - val_accuracy: 0.4219\n",
            "Epoch 124/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.8273 - accuracy: 0.4346 - val_loss: 2.3826 - val_accuracy: 0.3750\n",
            "Epoch 125/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 1.7652 - accuracy: 0.4622 - val_loss: 1.7266 - val_accuracy: 0.5078\n",
            "Epoch 126/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.7720 - accuracy: 0.4522 - val_loss: 1.9592 - val_accuracy: 0.4062\n",
            "Epoch 127/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 1.8273 - accuracy: 0.4438 - val_loss: 1.9669 - val_accuracy: 0.4141\n",
            "Epoch 128/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.8023 - accuracy: 0.4539 - val_loss: 1.9330 - val_accuracy: 0.4453\n",
            "Epoch 129/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.7900 - accuracy: 0.4581 - val_loss: 1.9667 - val_accuracy: 0.3828\n",
            "Epoch 130/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 1.7709 - accuracy: 0.4614 - val_loss: 1.8000 - val_accuracy: 0.4766\n",
            "Epoch 131/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.7894 - accuracy: 0.4597 - val_loss: 1.8388 - val_accuracy: 0.4766\n",
            "Epoch 132/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.7253 - accuracy: 0.4656 - val_loss: 1.8832 - val_accuracy: 0.4531\n",
            "Epoch 133/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.7877 - accuracy: 0.4555 - val_loss: 1.8550 - val_accuracy: 0.4531\n",
            "Epoch 134/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 1.7489 - accuracy: 0.4664 - val_loss: 1.8629 - val_accuracy: 0.4453\n",
            "Epoch 135/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 1.6996 - accuracy: 0.4639 - val_loss: 1.8601 - val_accuracy: 0.4453\n",
            "Epoch 136/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.7020 - accuracy: 0.4773 - val_loss: 1.7144 - val_accuracy: 0.4688\n",
            "Epoch 137/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.7002 - accuracy: 0.4723 - val_loss: 1.8645 - val_accuracy: 0.4219\n",
            "Epoch 138/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.6309 - accuracy: 0.4815 - val_loss: 1.7872 - val_accuracy: 0.4453\n",
            "Epoch 139/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.6594 - accuracy: 0.4924 - val_loss: 1.6962 - val_accuracy: 0.4766\n",
            "Epoch 140/300\n",
            "38/38 [==============================] - 10s 255ms/step - loss: 1.6549 - accuracy: 0.4866 - val_loss: 1.9624 - val_accuracy: 0.4219\n",
            "Epoch 141/300\n",
            "38/38 [==============================] - 10s 246ms/step - loss: 1.6970 - accuracy: 0.4841 - val_loss: 1.7517 - val_accuracy: 0.4922\n",
            "Epoch 142/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 1.6623 - accuracy: 0.4874 - val_loss: 1.7366 - val_accuracy: 0.4453\n",
            "Epoch 143/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.7808 - accuracy: 0.4723 - val_loss: 1.7535 - val_accuracy: 0.4688\n",
            "Epoch 144/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 1.6025 - accuracy: 0.4992 - val_loss: 1.9569 - val_accuracy: 0.3906\n",
            "Epoch 145/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.7028 - accuracy: 0.4815 - val_loss: 1.8336 - val_accuracy: 0.4219\n",
            "Epoch 146/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.5555 - accuracy: 0.5252 - val_loss: 1.7622 - val_accuracy: 0.4453\n",
            "Epoch 147/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.5595 - accuracy: 0.5143 - val_loss: 2.1551 - val_accuracy: 0.3594\n",
            "Epoch 148/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.6936 - accuracy: 0.4891 - val_loss: 1.8964 - val_accuracy: 0.4141\n",
            "Epoch 149/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.6820 - accuracy: 0.4874 - val_loss: 1.7437 - val_accuracy: 0.5000\n",
            "Epoch 150/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.6314 - accuracy: 0.5059 - val_loss: 1.8638 - val_accuracy: 0.3984\n",
            "Epoch 151/300\n",
            "38/38 [==============================] - 9s 239ms/step - loss: 1.5749 - accuracy: 0.5168 - val_loss: 1.7022 - val_accuracy: 0.4922\n",
            "Epoch 152/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.6418 - accuracy: 0.4958 - val_loss: 1.8112 - val_accuracy: 0.4922\n",
            "Epoch 153/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.6261 - accuracy: 0.5092 - val_loss: 1.6509 - val_accuracy: 0.4844\n",
            "Epoch 154/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 1.5282 - accuracy: 0.5252 - val_loss: 1.7291 - val_accuracy: 0.5078\n",
            "Epoch 155/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 1.6019 - accuracy: 0.4933 - val_loss: 1.7066 - val_accuracy: 0.5000\n",
            "Epoch 156/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.6118 - accuracy: 0.5084 - val_loss: 1.7766 - val_accuracy: 0.4844\n",
            "Epoch 157/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 1.5707 - accuracy: 0.5151 - val_loss: 1.7906 - val_accuracy: 0.4375\n",
            "Epoch 158/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.6269 - accuracy: 0.5034 - val_loss: 1.7740 - val_accuracy: 0.4766\n",
            "Epoch 159/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.4963 - accuracy: 0.5201INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 660ms/step - loss: 1.4963 - accuracy: 0.5201 - val_loss: 1.6844 - val_accuracy: 0.5312\n",
            "Epoch 160/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 1.5298 - accuracy: 0.5117 - val_loss: 1.7666 - val_accuracy: 0.4453\n",
            "Epoch 161/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.4611 - accuracy: 0.5378 - val_loss: 1.8654 - val_accuracy: 0.4453\n",
            "Epoch 162/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.5339 - accuracy: 0.5243 - val_loss: 1.6952 - val_accuracy: 0.4609\n",
            "Epoch 163/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.5675 - accuracy: 0.5193 - val_loss: 1.6104 - val_accuracy: 0.5312\n",
            "Epoch 164/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.4947 - accuracy: 0.5352 - val_loss: 1.5766 - val_accuracy: 0.5078\n",
            "Epoch 165/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.5580 - accuracy: 0.5294 - val_loss: 1.7436 - val_accuracy: 0.4922\n",
            "Epoch 166/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.5526 - accuracy: 0.5092 - val_loss: 1.7745 - val_accuracy: 0.4609\n",
            "Epoch 167/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.4885 - accuracy: 0.5554 - val_loss: 1.6279 - val_accuracy: 0.5156\n",
            "Epoch 168/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.5281 - accuracy: 0.5344 - val_loss: 1.7804 - val_accuracy: 0.4609\n",
            "Epoch 169/300\n",
            "38/38 [==============================] - 9s 245ms/step - loss: 1.4841 - accuracy: 0.5310 - val_loss: 1.6514 - val_accuracy: 0.5000\n",
            "Epoch 170/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.4630 - accuracy: 0.5587 - val_loss: 1.7342 - val_accuracy: 0.4766\n",
            "Epoch 171/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.4696 - accuracy: 0.5470 - val_loss: 1.7023 - val_accuracy: 0.4609\n",
            "Epoch 172/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.4716 - accuracy: 0.5503 - val_loss: 1.7851 - val_accuracy: 0.4766\n",
            "Epoch 173/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.6563 - accuracy: 0.4950 - val_loss: 1.9340 - val_accuracy: 0.4219\n",
            "Epoch 174/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.5473 - accuracy: 0.5159 - val_loss: 1.6712 - val_accuracy: 0.4922\n",
            "Epoch 175/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.5063 - accuracy: 0.5394 - val_loss: 1.7688 - val_accuracy: 0.4922\n",
            "Epoch 176/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.4550 - accuracy: 0.5596 - val_loss: 1.6376 - val_accuracy: 0.4766\n",
            "Epoch 177/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 1.4818 - accuracy: 0.5227 - val_loss: 1.8377 - val_accuracy: 0.4531\n",
            "Epoch 178/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.4240 - accuracy: 0.5612 - val_loss: 1.7106 - val_accuracy: 0.5234\n",
            "Epoch 179/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.4565 - accuracy: 0.5445 - val_loss: 1.6741 - val_accuracy: 0.4766\n",
            "Epoch 180/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.4659 - accuracy: 0.5470INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 667ms/step - loss: 1.4659 - accuracy: 0.5470 - val_loss: 1.4250 - val_accuracy: 0.5391\n",
            "Epoch 181/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.4292 - accuracy: 0.5638 - val_loss: 1.6254 - val_accuracy: 0.5000\n",
            "Epoch 182/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.3370 - accuracy: 0.5898 - val_loss: 1.6778 - val_accuracy: 0.4922\n",
            "Epoch 183/300\n",
            "38/38 [==============================] - 9s 239ms/step - loss: 1.3844 - accuracy: 0.5805 - val_loss: 1.5681 - val_accuracy: 0.4844\n",
            "Epoch 184/300\n",
            "38/38 [==============================] - 9s 239ms/step - loss: 1.4308 - accuracy: 0.5612 - val_loss: 1.7445 - val_accuracy: 0.4609\n",
            "Epoch 185/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.3725 - accuracy: 0.5772INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 664ms/step - loss: 1.3725 - accuracy: 0.5772 - val_loss: 1.5452 - val_accuracy: 0.5625\n",
            "Epoch 186/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.3725 - accuracy: 0.5688 - val_loss: 1.7234 - val_accuracy: 0.4844\n",
            "Epoch 187/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.4430 - accuracy: 0.5638 - val_loss: 1.6766 - val_accuracy: 0.5078\n",
            "Epoch 188/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.4145 - accuracy: 0.5705 - val_loss: 1.5446 - val_accuracy: 0.5312\n",
            "Epoch 189/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.3643 - accuracy: 0.5747 - val_loss: 1.8102 - val_accuracy: 0.5156\n",
            "Epoch 190/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.3689 - accuracy: 0.5772 - val_loss: 1.6812 - val_accuracy: 0.4922\n",
            "Epoch 191/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.3875 - accuracy: 0.5545 - val_loss: 2.1821 - val_accuracy: 0.4141\n",
            "Epoch 192/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.4849 - accuracy: 0.5470 - val_loss: 1.5666 - val_accuracy: 0.5391\n",
            "Epoch 193/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.3650 - accuracy: 0.5612 - val_loss: 1.6372 - val_accuracy: 0.5156\n",
            "Epoch 194/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.3512 - accuracy: 0.5688 - val_loss: 1.5356 - val_accuracy: 0.5547\n",
            "Epoch 195/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.3959 - accuracy: 0.5612 - val_loss: 1.6247 - val_accuracy: 0.4844\n",
            "Epoch 196/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.3225 - accuracy: 0.5814 - val_loss: 1.5711 - val_accuracy: 0.5156\n",
            "Epoch 197/300\n",
            "38/38 [==============================] - 10s 268ms/step - loss: 1.3502 - accuracy: 0.5822 - val_loss: 1.5831 - val_accuracy: 0.4922\n",
            "Epoch 198/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.4026 - accuracy: 0.5621 - val_loss: 1.5356 - val_accuracy: 0.5391\n",
            "Epoch 199/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.3537 - accuracy: 0.5772 - val_loss: 1.6620 - val_accuracy: 0.5078\n",
            "Epoch 200/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.3975 - accuracy: 0.5654 - val_loss: 1.7990 - val_accuracy: 0.4219\n",
            "Epoch 201/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.3284 - accuracy: 0.5898INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 25s 672ms/step - loss: 1.3284 - accuracy: 0.5898 - val_loss: 1.3651 - val_accuracy: 0.5781\n",
            "Epoch 202/300\n",
            "38/38 [==============================] - 9s 230ms/step - loss: 1.3646 - accuracy: 0.5797 - val_loss: 1.7764 - val_accuracy: 0.4219\n",
            "Epoch 203/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.3396 - accuracy: 0.6007 - val_loss: 1.6776 - val_accuracy: 0.5078\n",
            "Epoch 204/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.4373 - accuracy: 0.5621 - val_loss: 2.0242 - val_accuracy: 0.4141\n",
            "Epoch 205/300\n",
            "38/38 [==============================] - 9s 231ms/step - loss: 1.3315 - accuracy: 0.5948 - val_loss: 1.7720 - val_accuracy: 0.5234\n",
            "Epoch 206/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.3095 - accuracy: 0.6065 - val_loss: 1.7797 - val_accuracy: 0.4062\n",
            "Epoch 207/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.2613 - accuracy: 0.6040 - val_loss: 1.8700 - val_accuracy: 0.4141\n",
            "Epoch 208/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.3005 - accuracy: 0.5814 - val_loss: 1.8441 - val_accuracy: 0.4453\n",
            "Epoch 209/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.2426 - accuracy: 0.6116 - val_loss: 1.7256 - val_accuracy: 0.4844\n",
            "Epoch 210/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.2697 - accuracy: 0.6057 - val_loss: 1.7886 - val_accuracy: 0.4531\n",
            "Epoch 211/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.2669 - accuracy: 0.5898 - val_loss: 1.5280 - val_accuracy: 0.5156\n",
            "Epoch 212/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.2955 - accuracy: 0.5956 - val_loss: 1.7306 - val_accuracy: 0.4375\n",
            "Epoch 213/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.3111 - accuracy: 0.6049 - val_loss: 1.6582 - val_accuracy: 0.5078\n",
            "Epoch 214/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.2627 - accuracy: 0.6091 - val_loss: 1.7699 - val_accuracy: 0.4453\n",
            "Epoch 215/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.3053 - accuracy: 0.6032 - val_loss: 1.6220 - val_accuracy: 0.5078\n",
            "Epoch 216/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.2410 - accuracy: 0.6107 - val_loss: 1.4747 - val_accuracy: 0.5156\n",
            "Epoch 217/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.2923 - accuracy: 0.6049 - val_loss: 1.8762 - val_accuracy: 0.4453\n",
            "Epoch 218/300\n",
            "38/38 [==============================] - 9s 231ms/step - loss: 1.2240 - accuracy: 0.6275 - val_loss: 1.6626 - val_accuracy: 0.4922\n",
            "Epoch 219/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.2496 - accuracy: 0.6023 - val_loss: 1.4629 - val_accuracy: 0.5625\n",
            "Epoch 220/300\n",
            "38/38 [==============================] - 9s 239ms/step - loss: 1.2202 - accuracy: 0.6250 - val_loss: 1.7473 - val_accuracy: 0.4844\n",
            "Epoch 221/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.2102 - accuracy: 0.6351 - val_loss: 1.8349 - val_accuracy: 0.4688\n",
            "Epoch 222/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.2607 - accuracy: 0.6183 - val_loss: 1.8590 - val_accuracy: 0.4375\n",
            "Epoch 223/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.2348 - accuracy: 0.6250 - val_loss: 1.6346 - val_accuracy: 0.5312\n",
            "Epoch 224/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.2795 - accuracy: 0.5973 - val_loss: 1.5556 - val_accuracy: 0.5000\n",
            "Epoch 225/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.1490 - accuracy: 0.6468 - val_loss: 1.6094 - val_accuracy: 0.4844\n",
            "Epoch 226/300\n",
            "38/38 [==============================] - 9s 239ms/step - loss: 1.2875 - accuracy: 0.5998 - val_loss: 1.7390 - val_accuracy: 0.4844\n",
            "Epoch 227/300\n",
            "38/38 [==============================] - 10s 269ms/step - loss: 1.2226 - accuracy: 0.6116 - val_loss: 1.7650 - val_accuracy: 0.5000\n",
            "Epoch 228/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.2003 - accuracy: 0.6317 - val_loss: 1.5856 - val_accuracy: 0.5625\n",
            "Epoch 229/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.1480 - accuracy: 0.6292 - val_loss: 1.9049 - val_accuracy: 0.4141\n",
            "Epoch 230/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.2137 - accuracy: 0.6200 - val_loss: 1.8210 - val_accuracy: 0.4688\n",
            "Epoch 231/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.2066 - accuracy: 0.6158 - val_loss: 1.7147 - val_accuracy: 0.5000\n",
            "Epoch 232/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.2723 - accuracy: 0.6107 - val_loss: 1.7747 - val_accuracy: 0.4375\n",
            "Epoch 233/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.1908 - accuracy: 0.6326 - val_loss: 1.6278 - val_accuracy: 0.5312\n",
            "Epoch 234/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.1633 - accuracy: 0.6342 - val_loss: 1.9476 - val_accuracy: 0.4375\n",
            "Epoch 235/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.1530 - accuracy: 0.6409 - val_loss: 1.6595 - val_accuracy: 0.4922\n",
            "Epoch 236/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.2367 - accuracy: 0.6225 - val_loss: 1.5831 - val_accuracy: 0.5000\n",
            "Epoch 237/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.2502 - accuracy: 0.6091 - val_loss: 2.1507 - val_accuracy: 0.3984\n",
            "Epoch 238/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.0620 - accuracy: 0.6594 - val_loss: 1.7750 - val_accuracy: 0.4844\n",
            "Epoch 239/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.1959 - accuracy: 0.6384 - val_loss: 1.6458 - val_accuracy: 0.5000\n",
            "Epoch 240/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.1866 - accuracy: 0.6409 - val_loss: 1.8171 - val_accuracy: 0.5078\n",
            "Epoch 241/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.1871 - accuracy: 0.6133 - val_loss: 2.1442 - val_accuracy: 0.4062\n",
            "Epoch 242/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.1496 - accuracy: 0.6426 - val_loss: 1.6051 - val_accuracy: 0.5000\n",
            "Epoch 243/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.1788 - accuracy: 0.6435 - val_loss: 1.9888 - val_accuracy: 0.4219\n",
            "Epoch 244/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.1535 - accuracy: 0.6477 - val_loss: 1.6572 - val_accuracy: 0.4922\n",
            "Epoch 245/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.1874 - accuracy: 0.6384 - val_loss: 2.0572 - val_accuracy: 0.4297\n",
            "Epoch 246/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.1645 - accuracy: 0.6208 - val_loss: 1.5859 - val_accuracy: 0.4688\n",
            "Epoch 247/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.1238 - accuracy: 0.6594 - val_loss: 1.7411 - val_accuracy: 0.4766\n",
            "Epoch 248/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.1705 - accuracy: 0.6376 - val_loss: 1.5709 - val_accuracy: 0.5078\n",
            "Epoch 249/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 1.0893 - accuracy: 0.6535 - val_loss: 1.9224 - val_accuracy: 0.4453\n",
            "Epoch 250/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.1743 - accuracy: 0.6191 - val_loss: 1.7186 - val_accuracy: 0.4844\n",
            "Epoch 251/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 1.1529 - accuracy: 0.6393 - val_loss: 1.6479 - val_accuracy: 0.5469\n",
            "Epoch 252/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.1819 - accuracy: 0.6216 - val_loss: 2.0451 - val_accuracy: 0.4609\n",
            "Epoch 253/300\n",
            "38/38 [==============================] - 9s 239ms/step - loss: 1.2133 - accuracy: 0.6091 - val_loss: 1.9233 - val_accuracy: 0.4375\n",
            "Epoch 254/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.0688 - accuracy: 0.6527 - val_loss: 1.5569 - val_accuracy: 0.5312\n",
            "Epoch 255/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.1326 - accuracy: 0.6586 - val_loss: 1.8139 - val_accuracy: 0.4453\n",
            "Epoch 256/300\n",
            "38/38 [==============================] - 9s 231ms/step - loss: 1.0562 - accuracy: 0.6594 - val_loss: 1.6526 - val_accuracy: 0.4766\n",
            "Epoch 257/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.1136 - accuracy: 0.6560 - val_loss: 1.3948 - val_accuracy: 0.5625\n",
            "Epoch 258/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.1152 - accuracy: 0.6493 - val_loss: 1.6444 - val_accuracy: 0.4922\n",
            "Epoch 259/300\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.0516 - accuracy: 0.6837INFO:tensorflow:Assets written to: models.json/assets\n",
            "38/38 [==============================] - 26s 689ms/step - loss: 1.0516 - accuracy: 0.6837 - val_loss: 1.2848 - val_accuracy: 0.5859\n",
            "Epoch 260/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.0088 - accuracy: 0.6854 - val_loss: 1.7179 - val_accuracy: 0.4766\n",
            "Epoch 261/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.0152 - accuracy: 0.6820 - val_loss: 1.8009 - val_accuracy: 0.4688\n",
            "Epoch 262/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.1653 - accuracy: 0.6460 - val_loss: 1.8327 - val_accuracy: 0.4922\n",
            "Epoch 263/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.0530 - accuracy: 0.6762 - val_loss: 1.6573 - val_accuracy: 0.4922\n",
            "Epoch 264/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.0281 - accuracy: 0.6728 - val_loss: 1.5589 - val_accuracy: 0.5391\n",
            "Epoch 265/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.0943 - accuracy: 0.6711 - val_loss: 2.3866 - val_accuracy: 0.3750\n",
            "Epoch 266/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.0689 - accuracy: 0.6678 - val_loss: 2.2460 - val_accuracy: 0.4219\n",
            "Epoch 267/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 0.9986 - accuracy: 0.6913 - val_loss: 1.5071 - val_accuracy: 0.5469\n",
            "Epoch 268/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.0965 - accuracy: 0.6569 - val_loss: 1.8428 - val_accuracy: 0.4453\n",
            "Epoch 269/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.0558 - accuracy: 0.6686 - val_loss: 1.6018 - val_accuracy: 0.5312\n",
            "Epoch 270/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.1533 - accuracy: 0.6443 - val_loss: 1.7172 - val_accuracy: 0.5312\n",
            "Epoch 271/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.0552 - accuracy: 0.6812 - val_loss: 2.1620 - val_accuracy: 0.4219\n",
            "Epoch 272/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.0919 - accuracy: 0.6577 - val_loss: 1.9627 - val_accuracy: 0.4219\n",
            "Epoch 273/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.0236 - accuracy: 0.6971 - val_loss: 1.6348 - val_accuracy: 0.4922\n",
            "Epoch 274/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.0475 - accuracy: 0.6594 - val_loss: 2.1218 - val_accuracy: 0.3984\n",
            "Epoch 275/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.0572 - accuracy: 0.6569 - val_loss: 1.8258 - val_accuracy: 0.4766\n",
            "Epoch 276/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.0897 - accuracy: 0.6376 - val_loss: 1.6646 - val_accuracy: 0.5469\n",
            "Epoch 277/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 1.0791 - accuracy: 0.6586 - val_loss: 2.4198 - val_accuracy: 0.3828\n",
            "Epoch 278/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.0096 - accuracy: 0.6812 - val_loss: 1.7598 - val_accuracy: 0.4609\n",
            "Epoch 279/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 0.9800 - accuracy: 0.6854 - val_loss: 1.7443 - val_accuracy: 0.5234\n",
            "Epoch 280/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 1.0455 - accuracy: 0.6921 - val_loss: 1.9242 - val_accuracy: 0.4453\n",
            "Epoch 281/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.0934 - accuracy: 0.6661 - val_loss: 1.6912 - val_accuracy: 0.5156\n",
            "Epoch 282/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.0206 - accuracy: 0.6971 - val_loss: 1.6642 - val_accuracy: 0.5000\n",
            "Epoch 283/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 1.1068 - accuracy: 0.6628 - val_loss: 1.7515 - val_accuracy: 0.5000\n",
            "Epoch 284/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.0842 - accuracy: 0.6569 - val_loss: 1.6323 - val_accuracy: 0.4922\n",
            "Epoch 285/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 1.0169 - accuracy: 0.6837 - val_loss: 2.2292 - val_accuracy: 0.3984\n",
            "Epoch 286/300\n",
            "38/38 [==============================] - 9s 235ms/step - loss: 1.0495 - accuracy: 0.6644 - val_loss: 1.8072 - val_accuracy: 0.5078\n",
            "Epoch 287/300\n",
            "38/38 [==============================] - 9s 237ms/step - loss: 1.0472 - accuracy: 0.6737 - val_loss: 1.8614 - val_accuracy: 0.4922\n",
            "Epoch 288/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 0.9987 - accuracy: 0.6988 - val_loss: 2.3094 - val_accuracy: 0.4219\n",
            "Epoch 289/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.1161 - accuracy: 0.6762 - val_loss: 1.5614 - val_accuracy: 0.5547\n",
            "Epoch 290/300\n",
            "38/38 [==============================] - 10s 267ms/step - loss: 1.0644 - accuracy: 0.6762 - val_loss: 1.6556 - val_accuracy: 0.4844\n",
            "Epoch 291/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 0.9989 - accuracy: 0.6787 - val_loss: 1.7632 - val_accuracy: 0.4609\n",
            "Epoch 292/300\n",
            "38/38 [==============================] - 9s 232ms/step - loss: 0.9347 - accuracy: 0.7081 - val_loss: 1.5966 - val_accuracy: 0.5312\n",
            "Epoch 293/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.0897 - accuracy: 0.6619 - val_loss: 1.5938 - val_accuracy: 0.5000\n",
            "Epoch 294/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.0372 - accuracy: 0.6703 - val_loss: 1.9673 - val_accuracy: 0.4141\n",
            "Epoch 295/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 1.0166 - accuracy: 0.6795 - val_loss: 1.7321 - val_accuracy: 0.5391\n",
            "Epoch 296/300\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 0.9914 - accuracy: 0.6837 - val_loss: 1.6846 - val_accuracy: 0.4844\n",
            "Epoch 297/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.0378 - accuracy: 0.6787 - val_loss: 2.3420 - val_accuracy: 0.3750\n",
            "Epoch 298/300\n",
            "38/38 [==============================] - 9s 234ms/step - loss: 0.9943 - accuracy: 0.6896 - val_loss: 1.5907 - val_accuracy: 0.5156\n",
            "Epoch 299/300\n",
            "38/38 [==============================] - 9s 236ms/step - loss: 1.0385 - accuracy: 0.6527 - val_loss: 1.9903 - val_accuracy: 0.4453\n",
            "Epoch 300/300\n",
            "38/38 [==============================] - 9s 238ms/step - loss: 1.0519 - accuracy: 0.6703 - val_loss: 1.5988 - val_accuracy: 0.5312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j-1lbb6OiezE",
        "outputId": "94accbaf-1046-4822-d0ab-b216cb56aa1a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-3.18.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Collecting packaging~=20.9\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging~=20.9->tensorflowjs) (3.0.9)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.26.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (4.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.5.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (14.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.46.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.2.0)\n",
            "Installing collected packages: packaging, tensorflowjs\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed packaging-20.9 tensorflowjs-3.18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = face_celeb_train.history['accuracy']\n",
        "val_acc = face_celeb_train.history['val_accuracy']\n",
        "\n",
        "loss = face_celeb_train.history['loss']\n",
        "val_loss = face_celeb_train.history['val_loss']\n",
        "epochs_range=range(300)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WoDiYkfW7wTk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "590c14f9-ae11-49a7-c9ba-00e31a61e1a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model in JSON file \n",
        "from tensorflow.keras.models import model_from_json\n",
        "model_in_json = model.to_json()\n",
        "with open('model.json','w') as json_file:\n",
        "  json_file.write(model_in_json)"
      ],
      "metadata": {
        "id": "Eh7PDNP47zbN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading model from JSON file\n",
        "model_file = open('model.json','r')\n",
        "json_model=model_file.read()\n",
        "model2=model_from_json(json_model)\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "CBeVGRM071PB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4abc6008-0319-4f52-a90d-b4005e8112b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 64)      4864      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 256)       147712    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 1024)      4719616   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 8, 1024)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8, 8, 1024)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              268439552 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 26)                106522    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 291,379,738\n",
            "Trainable params: 291,379,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/AI/NhanDienKhuonMat/face.h5')\n",
        "model.save('/content/drive/MyDrive/AI/NhanDienKhuonMat/face.hdf5')"
      ],
      "metadata": {
        "id": "6AgxJXzLi-MJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yImilovwjV-K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}